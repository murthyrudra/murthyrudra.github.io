---
layout: about
title: about
permalink: /
subtitle: Browses memes and watches series to escape from reality.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  # more_info: >
  #   <p>555 your office number</p>
  #   <p>123 your address street</p>
  #   <p>Your City, State 12345</p>

selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: true
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

### About Me? 

Hmmm, I am an atom in the universe who is trying his best at *adulting*..?  
I wanted to become an over-achiever but ended up becoming an overthinker ðŸ¤·  

I am currently working as a Research Scientist at IBM Research, India. I pursued my PhD from [Center For Indian Language Technology](http://www.cfilt.iitb.ac.in/) lab headed by [Professor. Pushpak Bhattacharyya](https://www.cse.iitb.ac.in/~pb/). My area of interest is using Deep Multilingual Learning to various Natural Language Processing(NLP) tasks. 


#### Research Summary

> **Pinky:** Gee, Brain, What do you want to do today?  
> **Brain:** The same thing we do everyday, Pinky. Borrow features from high-resource language to improve NLP Task performance in low-resource languages

I am broadly interested in Natural Language Processing (NLP) for low-resource languages, specifically Indic languages. Recently, I have garnered interest in **Multilingual Learning for NLP in Low-Resource Languages**. Low-resource languages do not have sufficient data, tools, and other resources (leading to data sparsity) to successfully train existing machine learning models for any NLP task. My current focus is on borrowing features (implicitly statistics) from one or more related languages (multilingual learning). 
